{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* At training time KNN learns nothing. Computation on test time\n",
    "* Assign a class to new data point based on neighbors. (we use mode in categorical data)\n",
    "* Here data is the model VS in decision tree model is tree learned from data.\n",
    "* Identify numeric value of data point based on neighbors (mean/median) (regression task)\n",
    "* Also known as instance based learning, case based reasoning, lazy learning.\n",
    "* Weighted mean/mode of entire data. Giver higher weight to near by point\n",
    "* Process\n",
    "    - Pick number of neighbors K you want to use for classification or regression\n",
    "    - Choose method to measure distance (Ex. euclidean)\n",
    "    - Keep datasets with records\n",
    "    - Training\n",
    "        - For every new point identify the number of nearest neighbors you picked using method you chose\n",
    "        - Let them vote for classification or take mean/median for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision boundaries\n",
    "* For decision tree it is line parallel to dimension\n",
    "* For KNN it looks like Voronoi diagram: Each point in a convex hull is closest to the sample inside the convex hull than to any other sample.\n",
    "* Boundary is created as,\n",
    "    - Connect two training data, find mid point of that line, draw line perpendicular to it, that is your boundary.\n",
    "![](images/knn_vonoroi.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As it has very complex boundary, per training there is a convex hull. It has good chance of overfitting.\n",
    "* Noisy training is also an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing K\n",
    "* As complexity of space grows, accuracy comes down and you need more data\n",
    "* Increasing K can reduce overfit, suppose K = 1 and we have 1 outlier/noise because of it all other point outside it will be classified wrongly. Beyond a value accuracy starts decreasing.\n",
    "* Play with value of k with validation set.\n",
    "* For binary number of classes, choose odd K to break the tie. For 3 class, avoid multiple of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN problems\n",
    "* Scaling is important\n",
    "    -Attributes with larger range can nominate (Normalize it)\n",
    "    - Categorical and ordinal variables need to be handled nicely\n",
    "* Curse of dimensionality\n",
    "    - KNN works well with tall dataset, low dimensional dataset.\n",
    "        - Low dimension leads to low time to compute distance.\n",
    "    - High dimensionality leads to sparsity (widely spread out). KNN assumes points is representative around it, so because of sparsity and lack of data we may end up in wrong prediction.\n",
    "    - Reduce dimension\n",
    "        - Correlation (Age and birth year) Drop one of the feature\n",
    "        - Info gain (Select top N features that are significantly provide more info) Wrapper method like forward selection, backward elimination\n",
    "        - Weighting attributes\n",
    "            - PCA\n",
    "* Large model size\n",
    "    - Data = model\n",
    "    - Large model consumes memory.\n",
    "* Large execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with KNN\n",
    "\n",
    "#### R-KNN (Random KNN)\n",
    "* TO be done,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilson Editing (KNN for outlier detection)\n",
    "* In KNN at boundary we might NOT get smooth boundary, because of noise\n",
    "![](images/knn_wilson_editing.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We want to remove outliers.\n",
    "* Remove point that do not agree with the majority of their K nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Imputation (KNN as missing value imputation)\n",
    "* KNN is impacted by missing values\n",
    " * Imputation can be done by\n",
    "     - Case detection: Discarding all instanced with missing values for at least 1 features\n",
    "     - Mean imputation\n",
    "     -Median imputation\n",
    "     - KNN imputation : Try to figure out other similar instances using available features. After finding K nearest neighbors, use mean or median imputation among that K instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speeding up KNN with KMeans\n",
    "* Using KMeans we can come up with rough approximation to eliminate most points. Take entire dataset, cluster it. Each cluster has centroid.When new point comes in, compute K euclidean distance from those centroid. Nearest cluster is X. Now X has a lot less instances than entire dataset.\n",
    "* From that cluster compute KNN.\n",
    "* We can apply KMeans in hierarchical manner, i.e when you find one cluster, apply KMeans again. In the same way drive more deeper.\n",
    "\n",
    "#### Other methods\n",
    "* Condensation method\n",
    "    - Does not preserve original data, It saves time like Kmeans, but also save memory\n",
    "    - Take entire dataset, divide in point you retain and points throw away\n",
    "    - Retained points are called prototypes, Thrown away points are absorb points\n",
    "* Locality Sensitive Hashing\n",
    "    - Having many object and want to find approximately duplicate objects. LSH gives us whether it is duplicate or not. We can set similarity threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Measure\n",
    "* The similarity measure is the measure of how much alike two data objects are.\n",
    "* Make sure to normalize features, otherwise large range of feature will dominate the result.\n",
    "* Similarity are measured in the range 0 to 1\n",
    "\n",
    "#### Euclidean Distance\n",
    "* Best for dense and continuous data\n",
    "![](images/KNN_euclidean.PNG)\n",
    "\n",
    "#### Manhattan Distance (L1 length, L1 norm, rectilinear distance, Manhattan length,Minkowskiâ€™s L1 distance, taxi-cab metric, city block distanc)\n",
    "* Distance between two points is the sum of the absolute differences of their Cartesian coordinates.\n",
    "* It is the total sum of the difference between the x-coordinates  and y-coordinates.\n",
    "* P1 is (x1,y1) P2 is (x2,y2)\n",
    "* Manhattan distance  = |x1 - x2| + |y1 - y2|\n",
    "\n",
    "#### Minkowski distance\n",
    "* Generalized metric from Euclidean and Manhattan distance\n",
    "$$D(i,j) = \\sqrt[\\lambda]{\\sum_{k=0}^{n-1}|Y_{ik} - y_{jk}|^\\lambda}$$ \n",
    "\n",
    "* K is the index of the feature. n is total number of features.\n",
    "* $\\lambda$ values are usually 1,2 or $\\inf$\n",
    "* $\\lambda$  = 1 is Manhattan distance\n",
    "* $\\lambda$  = 2 is Euclidean distance\n",
    "* $\\lambda$  = inf is Chebyshev distance\n",
    "\n",
    "#### Cosine similarity\n",
    "$$Similarity(A,B) = \\frac{A \\cdot B }{||A||||B||}$$\n",
    "*  Normalized dot product of 2 instances.\n",
    "* Here we are finding cos angle between 2 data points.\n",
    "* Angle 0 meaning similar and similarity 1\n",
    "* angle 90, similarity 0\n",
    "* Angle 180, similarity - 1\n",
    "\n",
    "#### Jaccard Similarity\n",
    "*  The Jaccard similarity measures the similarity between finite sample sets and is defined as the cardinality of the intersection of sets divided by the cardinality of the union of the sample sets. \n",
    "\n",
    "$$J(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Passing missing value or non numerical values to model in sklearn will return error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is instance based algo, try to find similar, labeled example from the training set for each instance in the test set and use them to predict label.\n",
    "* It relies on previous instance to make prediction, it does NOT learn relationship between feature and target.\n",
    "* As entire training set is used to find new instance's nearest neighbor to make label prediction, this algo does NOT scale well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/knn_complexity.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8eddb6c14f62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mp_diffs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "p_diffs = []\n",
    "\n",
    "size = df2.shape[0]\n",
    "\n",
    "for _ in range(10000):\n",
    "    s_df2 = df2.sample(size, replace=True)\n",
    "    s_treatment_df = s_df2.query('group==\"treatment\"')\n",
    "    s_control_df = s_df2.query('group==\"control\"')\n",
    "    s_new_page_converted = np.random.binomial(1, new_cnv_rate, s_treatment_df.shape[0])\n",
    "    s_old_page_converted = np.random.binomial(1, old_cnv_rate, s_control_df.shape[0])\n",
    "    p_diffs.append(s_new_page_converted.mean()-s_old_page_converted.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10000):\n",
    "    x = np.random.binomial(1, 0.2, 5)\n",
    "    y = np.random.binomial(1, 0.3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
